{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLHiTPXNTf2a"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oTuT5CsaTigz"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNM-D0pLXZeR"
      },
      "source": [
        "# Gemini API: Chat with SQL using LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRZo8H09Bs6u"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ranasaurus9/gemini-workshop/blob/main/4-Chat_with_SQL_using_langchain.ipynb\"><img src = \"../../images/colab_logo_32px.png\"/>Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOGNjAZMwMIk"
      },
      "source": [
        "Reading an SQL database can be challenging for humans. However, with accurate prompts, Gemini models can generate answers based on the data. Through the use of the Gemini API, you will be able retrieve necessary information by chatting with a SQL database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaSSapCIcoxy"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai langchain langchain-community langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBoPE7f7cmKA"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "from langchain.chains import create_sql_query_chain, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQOGMejVu-6D"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysayz8skEfBW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzyyOcsUR0HO"
      },
      "source": [
        "## Setting up the database\n",
        "To query a database, you first need to set one up.\n",
        "\n",
        "1. **Load the California Housing Dataset:** Load the dataset from sklearn.datasets and extract it into a DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lK85M4XGRzsM"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "california_housing_bunch = fetch_california_housing(as_frame=True)\n",
        "california_housing_df = california_housing_bunch.frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIjbnY4X_Kwd"
      },
      "source": [
        "2. **Connect to the SQLite database:** The database will be stored in the specified file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kbqtjo4V2qM"
      },
      "outputs": [],
      "source": [
        "conn = sqlite3.connect(\"mydatabase.db\")\n",
        "\n",
        "# Write the DataFrame to a SQL table named 'housing'.\n",
        "california_housing_df.to_sql(\"housing\", conn, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7ChiDUmXC3K"
      },
      "outputs": [],
      "source": [
        "# Create an SQLDatabase object\n",
        "db = SQLDatabase.from_uri(\"sqlite:///mydatabase.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHGQdREVYFxo"
      },
      "source": [
        "## Question to query\n",
        "With the database connection established, the `SQLDatabase` object now contains information about our database, which the model can access.\n",
        "\n",
        "You can now start asking the LLM to generate queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0xP-OStxDW8"
      },
      "outputs": [],
      "source": [
        "# you can see what information is available\n",
        "Markdown(db.get_table_info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFnV5-dUaa77"
      },
      "outputs": [],
      "source": [
        "# Define query chain\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "write_query_chain = create_sql_query_chain(llm, db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EdrtzVX0zcm"
      },
      "source": [
        "You use `create_sql_query_chain` that fits our database. It provides default prompts for various types of SQL including Oracle, Google SQL, MySQL and more.\n",
        "\n",
        "\n",
        "In this case, default prompt is suitable for the task. However, feel free to experiment with writing this part of our chain yourself to suit your preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2TjWih70ro6"
      },
      "outputs": [],
      "source": [
        "Markdown(write_query_chain.get_prompts()[0].template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGONOILk0sr2"
      },
      "outputs": [],
      "source": [
        "response = write_query_chain.invoke({\"question\": \"What is the total population?\"})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rwKuD6eYhzv"
      },
      "outputs": [],
      "source": [
        "db.run('SELECT SUM(\"Population\") FROM housing')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb_72hgXagco"
      },
      "source": [
        "Great! The SQL query is correct, but it needs proper formatting before it can be executed directly by the database.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZOGsW9YcL-I"
      },
      "source": [
        "## Validating the query\n",
        "You will pass the output of the previous query to a model that will extract just the SQL query and ensure its validity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptuPPTordp6G"
      },
      "outputs": [],
      "source": [
        "validate_prompt = PromptTemplate(\n",
        "    input_variables=[\"not_formatted_query\"],\n",
        "    template=\"\"\"You are going to receive a text that contains a SQL query. Extract that query.\n",
        "    Make sure that it is a valid SQL command that can be passed directly to the Database.\n",
        "    Avoid using Markdown for this task.\n",
        "    Text: {not_formatted_query}\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KP9yy1edRfJ"
      },
      "outputs": [],
      "source": [
        "validate_chain = write_query_chain | validate_prompt | llm | StrOutputParser()\n",
        "validate_chain.invoke({\"question\": \"What is the total population?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oskPmggygOJP"
      },
      "source": [
        "## Automatic querying\n",
        "Now, let's automate the process of querying the database using *QuerySQLDataBaseTool*. This tool can receive text from previous parts of the chain, execute the query, and return the answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTfFkHVgcDuo"
      },
      "outputs": [],
      "source": [
        "execute_query = QuerySQLDataBaseTool(db=db)\n",
        "execute_chain = validate_chain | execute_query\n",
        "execute_chain.invoke({\"question\": \"What is the total population?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amQh9IvQlBH0"
      },
      "source": [
        "## Generating answer\n",
        "You are almost done!\n",
        "\n",
        "To enhance our output, you'll use LLM not only to get the number but to get properly formatted and natural language response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "658lkr4xlD6q"
      },
      "outputs": [],
      "source": [
        "answer_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are going to receive a original user question, generated SQL query, and result of said query. You should use this information to answer the original question. Use only information provided to you.\n",
        "\n",
        "Original Question: {question}\n",
        "SQL Query: {query}\n",
        "SQL Result: {result}\n",
        "Answer: \"\"\"\n",
        ")\n",
        "\n",
        "answer_chain = (\n",
        "    RunnablePassthrough.assign(query=validate_chain).assign(\n",
        "        result=itemgetter(\"query\") | execute_query\n",
        "    )\n",
        "    | answer_prompt | llm | StrOutputParser()\n",
        ")\n",
        "\n",
        "answer_chain.invoke({\"question\": \"What is the total population?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJmceCo2Lebi"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Congratulations! You've successfully created a functional chain to interact with SQL. Now, feel free to explore further by asking different questions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Chat_with_SQL_using_langchain.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
